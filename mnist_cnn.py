# -*- coding: utf-8 -*-
"""mnist_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZYCCoSGF46pmdkk8OY7c3tSulDzeumNW
"""

import tensorflow as tf
from tensorflow.keras.layers import Dense,MaxPooling2D,Flatten,Conv2D
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()
print(x_train.shape)
print(x_test.shape)

plt.figure(figsize=(7,7))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.title("label = "+str(y_train[i]))
    plt.imshow(x_train[i],cmap="gray")
    plt.axis()
plt.show()

x_train = np.reshape(x_train , (x_train.shape[0] , x_train.shape[1] , x_train.shape[2] , 1)) #reshape in 4D x_train
x_test = np.reshape(x_test , (x_test.shape[0] , x_test.shape[1] , x_test.shape[2] , 1)) # reshape in 4D x_test

x_train = x_train.astype('float32') / 255 # normalizing in range 0 to 1
x_test = x_test.astype('float32') / 255 # normalizing in range 0 to 1

y_train = to_categorical(y_train , 10) # one hot encoding of y_train
y_test = to_categorical(y_test , 10) # one hot encoding of y_test

model = tf.keras.Sequential() # define sequential model

model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='valid',activation="relu",input_shape=(28,28,1))) # convlution layer
model.add(MaxPooling2D(pool_size = (2,2))) # Maxpooling for down sampling
model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',activation="relu")) # second Convolution layer
model.add(MaxPooling2D(pool_size = (2,2))) # Maxpooling for down sampling
model.add(Flatten()) # Flatten layer for 1D transformation
model.add(Dense(units = 64 , activation = "relu")) # Fully connected layer of 64 units
model.add(Dense(units = 10 , activation = "softmax")) # output layer with 10 units as number of class = 10

model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=['acc'])
model.summary()

model.fit(x_train,y_train,batch_size = 32 , epochs = 10)

total_loss,test_acc = model.evaluate(x_test,y_test)
print("accuracy",test_acc)

# x_test_flattened = x_test.reshape(len(x_test),28*28)
probs = model.predict(x_test)
preds = np.argmax(probs,axis=1)
print(preds[5])
plt.imshow(x_test[5],cmap='gray')
plt.show()