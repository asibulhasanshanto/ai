# -*- coding: utf-8 -*-
"""augmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/100_ujd8vJZyYEbC4rT7JpUjM-teVrHzo
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Input, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import mnist
from tensorflow.keras.preprocessing.image import ImageDataGenerator

(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape)
print(x_test.shape)

plt.figure(figsize=(7,7))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.title("label = "+str(y_train[i]))
    plt.imshow(x_train[i],cmap="gray")
    plt.axis()
plt.show()

# 2d-> 3d
x_train = x_train.reshape((x_train.shape[0], 28 , 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28 , 28, 1))
print(x_train.shape)
print(x_test.shape)

y_train = to_categorical(y_train) # if image is 4 then y_train array index 4 is 1 other is 0
y_test = to_categorical(y_test )

x_train = x_train / 255.0
x_test = x_test / 255.0

model1= Sequential([
        Flatten(input_shape=(28, 28, 1)), # channel 1 / gray scale
        Dense(512, activation = 'relu', name = "hidden_layer-1"),
        Dense(256, activation = 'relu', name = "hidden_layer-2"),
        Dense(128, activation = 'relu', name = "hidden_layer-3"),
        Dense(64, activation = 'relu', name = "hidden_layer-4"),
        Dense(10, activation = 'softmax', name = "output_layer") # 10 because 10 multi-layer output
])
model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model1.summary()
# For example, if you have 60,000 training samples and a batch size of 32, there will be 60,000/32 = 1875 batches in an epoch.
# In the example you mentioned, a batch size of 32 means that 32 training samples
# will be processed together before the model's weights are updated.

model1.fit(x_train, y_train, epochs= 20)

_,accuracy = model1.evaluate(x_test, y_test, verbose = 0)
print("Accuracy on Test dataset = ", format(accuracy*100,'.2f'),'%')

# data augmentation used for increase dataset and diversity

datagen = ImageDataGenerator(
    rotation_range = 10,# 10% rotate
    zoom_range  = 0.2,# 20% zoom in and out
    width_shift_range = 0.1,# Specify the range of random horizontal and vertical shifts that can be applied to the images.
    height_shift_range = 0.1,
    shear_range = 0.1
)

datagen.fit(x_train)

model2= Sequential([
        Flatten(input_shape=(28, 28, 1)),
        Dense(512, activation = 'relu', name = "hidden_layer-1"),
        Dense(256, activation = 'relu', name = "hidden_layer-2"),
        Dense(128, activation = 'relu', name = "hidden_layer-3"),
        Dense(64, activation = 'relu', name = "hidden_layer-4"),
        Dense(10, activation = 'softmax', name = "output_layer")
])
model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model2.summary()

model2.fit(datagen.flow(x_train, y_train, batch_size=32), epochs= 20)

_,accuracy = model2.evaluate(x_test, y_test, verbose = 0)
print("Accuracy on Test dataset = ", format(accuracy*100,'.2f'),'%')